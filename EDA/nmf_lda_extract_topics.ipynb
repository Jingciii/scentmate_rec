{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://fragrance:fragrance@35.164.86.3:27017/fragrance\")\n",
    "db = client.fragrance\n",
    "collection = db.perfume_comments\n",
    "raw_df = pd.DataFrame(list(collection.find({}, {'_id': 0}))) # not including _id column\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus(df):\n",
    "    '''Build corpus from dataframe'''\n",
    "    corpus = []\n",
    "    for doc in df['comments']:\n",
    "        corpus.append(doc[0])\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_to_words(corpus):\n",
    "    '''Use jieba to split Chinese text return a list string of words'''\n",
    "    seg_list = []\n",
    "    for doc in corpus:\n",
    "        words = jieba.cut(doc)\n",
    "        string = \" \".join(words)\n",
    "        seg_list.append(string)\n",
    "    return seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perfume_stopwords():\n",
    "    '''Get stopwords file customized for perfume reviews, return a list of words'''\n",
    "    with io.open('models/chinese_stopwords.txt', 'r', encoding='utf8') as f:\n",
    "        stpwdlst = f.read().split()\n",
    "    return stpwdlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vectorized_mat(seg_list, use_tfidf, stop_words, max_features=1000):\n",
    "    '''Get TFIDF or TF matrix from tokenized documents corpus\n",
    "    If use_tfidf is True --> TFIDF Vectorizer\n",
    "    If user_tfidf is False --> Count Vectorizer'''\n",
    "    Vectorizer = TfidfVectorizer if use_tfidf else CountVectorizer\n",
    "    vectorizer_model = Vectorizer(stop_words=stop_words,\n",
    "                           analyzer='word',\n",
    "                           max_features=max_features)\n",
    "    vec_docs = vectorizer_model.fit_transform(seg_list) # return a sparse matrix\n",
    "    return vectorizer_model, vec_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using NMF and LDA in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    '''Display topics generated from NMF and LDA mdoel'''\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/hw/_zx541317jn081zp18m2fp900000gn/T/jieba.cache\n",
      "Loading model cost 0.639 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize corpus\n",
    "stpwdlst = get_perfume_stopwords()\n",
    "corpus = get_corpus(raw_df)\n",
    "seg_list = split_to_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NMF is able to use tf-idf, thus fit documents to TFIDF\n",
    "tfidf_vectorizer, tfidf_docs = get_vectorized_mat(seg_list,\n",
    "                                                  use_tfidf=True,\n",
    "                                                  stop_words=stpwdlst,\n",
    "                                                  max_features=1000)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model, thus fit to CountVectorizer\n",
    "countvectorizer, tf_docs = get_vectorized_mat(seg_list,\n",
    "                                              use_tfidf=False,\n",
    "                                              stop_words=stpwdlst,\n",
    "                                              max_features=1000)\n",
    "tf_feature_names = countvectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_topics = 10\n",
    "no_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found by NMF: \n",
      "Topic 0:\n",
      "留香 时间 香气 气息 温柔 特别 麝香 柠檬 名字 少女 辛辣 温暖 甜美 女人 香调 性感 整体 浓郁 不错 脂粉\n",
      "Topic 1:\n",
      "玫瑰 沉香 荔枝 牡丹 花瓣 玫瑰花 女王 檀香 少女 真实 蜂蜜 绽放 丝带 乌木 幽幽 醋栗 馥郁 广藿香 大气 甜美\n",
      "Topic 2:\n",
      "木质 香根草 气息 树脂 香辛 鸢尾 草本 干燥 沉香 东方 胡椒 雪松 柑橘 整体 粉感 融合 烟草 温暖 烟熏 檀木\n",
      "Topic 3:\n",
      "花香 果香 果味 栀子花 粉感 浓郁 柔和 绿意 白色 晚香玉 整体 白花 淡淡的 牡丹 甜甜的 脂粉 混合 优雅 木兰 百合\n",
      "Topic 4:\n",
      "香草 广藿香 琥珀 美食 巧克力 焦糖 温暖 麝香 水果 不错 奶油 柔滑 甜味 甜美 杏仁 焚香 东方 檀香 浆果 甜腻\n",
      "Topic 5:\n",
      "皮革 烟草 烟熏 男人 琥珀 李子 男性 元素 奢华 粉质 鸢尾花 苦涩 爱慕 动物 传统 黑暗 强势 慢慢 贵族 深邃\n",
      "Topic 6:\n",
      "香味 甜甜的 皮肤 时间 持续 持久 粉末 甜味 元素 留香 柔和 混合 不错 扩散 融合 特别 淡淡的 质感 水果 无花果\n",
      "Topic 7:\n",
      "好闻 特别 超级 男香 持久 淡淡的 舒服 冬天 朋友 香调 奶味 夏天 专柜 牡丹 果香 木质 温婉 魅力 芒果 大众\n",
      "Topic 8:\n",
      "茉莉 白花 晚香玉 栀子 栀子花 吲哚 铃兰 橙花 麝香 茉莉花 百合 浓郁 香气 白色 桃子 依兰 馥郁 分辨 佛手柑 淡雅\n",
      "Topic 9:\n",
      "清新 柑橘 柠檬 薄荷 夏天 干净 清爽 橘子 柚子 水生 绿茶 合成 清凉 中性 麝香 夏日 调和 琥珀 罗勒 尖锐\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics found by NMF: \")\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics found by LDA: \n",
      "Topic 0:\n",
      "温柔 性感 名字 特别 广藿香 烟草 男香 胡椒 木质 风格 男人 香调 调香 好闻 气息 气质 品牌 男性 柠檬 辛辣\n",
      "Topic 1:\n",
      "花香 女人 香精 香草 杏仁 甜腻 美食 气息 香味 五号 香气 巧克力 感受 甜美 果香 年轻 优雅 生活 浓郁 瓶身\n",
      "Topic 2:\n",
      "玫瑰 花香 茉莉 气息 白花 麝香 香气 晚香玉 清新 甜美 温柔 果香 琥珀 橙花 优雅 栀子 混合 浓郁 清甜 整体\n",
      "Topic 3:\n",
      "香根草 辛辣 气息 檀香 欲望 东方 年代 时代 故事 改版 回忆 老版 老香 香料 元素 表达 男人 岁月 经历 新版\n",
      "Topic 4:\n",
      "脂粉 百合 康乃馨 海水 图书馆 苦艾 海洋 宁静 分装 海风 lys 蓝毒 珠宝 地中海 法国 调香 故事 液体 巴黎 第一个\n",
      "Topic 5:\n",
      "鸢尾 沉香 紫罗兰 香料 木质 乌木 动物 麝香 乳香 东方 檀香 泥土 藏红花 质感 潮湿 天然 迪奥 没药 粉质 树脂\n",
      "Topic 6:\n",
      "清新 柑橘 香味 留香 夏天 柠檬 木质 好闻 混合 水生 无花果 不错 绿茶 麝香 持久 特别 清爽 干净 甜味 扩散\n",
      "Topic 7:\n",
      "留香 薰衣草 少女 时间 清新 柠檬 香气 特别 男香 香味 好闻 香调 清爽 不错 花果 花香 冬天 女生 气息 衣服\n",
      "Topic 8:\n",
      "木质 皮革 琥珀 柑橘 香草 气息 树脂 香气 草本 焚香 香辛 温暖 广藿香 整体 香根草 清新 干燥 融合 烟熏 花香\n",
      "Topic 9:\n",
      "香味 时间 留香 柔和 花香 香草 元素 广藿香 整体 质感 粉末 紫罗兰 皮肤 推荐 柔滑 橙花 美食 水果 联想 绿色\n"
     ]
    }
   ],
   "source": [
    "print(\"Topics found by LDA: \")\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 54.9188457952\n"
     ]
    }
   ],
   "source": [
    "W = nmf.fit_transform(tfidf_docs)\n",
    "H = nmf.components_\n",
    "print 'reconstruction error:', nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using LDA Model in Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_clean = [doc.split() for doc in seg_list]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
    "dictionary = corpora.Dictionary(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(ldamodel.print_topics(num_topics=10, num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that NMF gives better topics, go with NMF with 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hand_label_topics(H, vocabulary):\n",
    "    '''\n",
    "    Print the most influential words of each latent topic, and prompt the user\n",
    "    to label each topic. The user should use their humanness to figure out what\n",
    "    each latent topic is capturing.\n",
    "    '''\n",
    "    hand_labels = []\n",
    "    for i, row in enumerate(H):\n",
    "        top_five = np.argsort(row)[::-1][:20]\n",
    "        print 'topic', i\n",
    "        print '-->', ' '.join(vocabulary[top_five])\n",
    "        label = raw_input('please label this topic: ')\n",
    "        hand_labels.append(label)\n",
    "        print\n",
    "    return hand_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = np.array(tfidf_feature_names)\n",
    "hand_labels = hand_label_topics(H, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_dict = {}\n",
    "for i, topic in enumerate(hand_labels):\n",
    "    topic_dict[i] = topic.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_topic = {}\n",
    "for i, row in enumerate(W):\n",
    "    perfume_topic[i] = topic_dict[np.argsort(row)[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert dictionary to dataframe for join convenience\n",
    "perfume_topic_df = pd.DataFrame.from_dict(perfume_topic, orient='index')\n",
    "# change coumn name in perfume_topic_df\n",
    "perfume_topic_df.rename(columns={0:'keywords'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perfume_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_df = raw_df.join(perfume_topic_df, how='left')\n",
    "keywords_df.drop(['url'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords_df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
